{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83cf7f4",
   "metadata": {},
   "source": [
    "# Optional Lab: Linear Regression using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92335bb4",
   "metadata": {},
   "source": [
    "There is an open-source, commercially usable machine learning toolkit called [scikit-learn](https://scikit-learn.org/stable/index.html). This toolkit contains implementations of many of the algorithms that you will work with in this course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd8690",
   "metadata": {},
   "source": [
    "## Goals\n",
    "In this lab you will:\n",
    "- Utilize  scikit-learn to implement linear regression using a close form solution based on the normal equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1bfb9",
   "metadata": {},
   "source": [
    "## Tools\n",
    "You will utilize functions from scikit-learn as well as matplotlib and NumPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8933365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lab_utils_multi import load_house_data\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eeaf53",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2\"></a>\n",
    "# Linear Regression, closed-form solution\n",
    "Scikit-learn has the [linear regression model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) which implements a closed-form linear regression.\n",
    "\n",
    "Let's use the data from the early labs - a house with 1000 square feet sold for \\\\$300,000 and a house with 2000 square feet sold for \\\\$500,000.\n",
    "\n",
    "| Size (1000 sqft)     | Price (1000s of dollars) |\n",
    "| ----------------| ------------------------ |\n",
    "| 1               | 300                      |\n",
    "| 2               | 500                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b78b7",
   "metadata": {},
   "source": [
    "### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e935cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([1.0, 2.0])   #features\n",
    "y_train = np.array([300, 500])   #target value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec411fa6",
   "metadata": {},
   "source": [
    "### Create and fit the model\n",
    "The code below performs regression using scikit-learn. \n",
    "The first step creates a regression object.  \n",
    "The second step utilizes one of the methods associated with the object, `fit`. This performs regression, fitting the parameters to the input data. The toolkit expects a two-dimensional X matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b0c562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "#X must be a 2-D Matrix\n",
    "linear_model.fit(X_train.reshape(-1, 1), y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446d277",
   "metadata": {},
   "source": [
    "### View Parameters \n",
    "The $\\mathbf{w}$ and $\\mathbf{b}$ parameters are referred to as 'coefficients' and 'intercept' in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43908126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [200.], b = 100.00\n",
      "'manual' prediction: f_wb = wx+b : [240100.]\n"
     ]
    }
   ],
   "source": [
    "b = linear_model.intercept_\n",
    "w = linear_model.coef_\n",
    "print(f\"w = {w:}, b = {b:0.2f}\")\n",
    "print(f\"'manual' prediction: f_wb = wx+b : {1200*w + b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c005d",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "Calling the `predict` function generates predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2697357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on training set: [300. 500.]\n",
      "Prediction for 1200 sqft house: $240100.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = linear_model.predict(X_train.reshape(-1, 1))\n",
    "\n",
    "print(\"Prediction on training set:\", y_pred)\n",
    "\n",
    "X_test = np.array([[1200]])\n",
    "print(f\"Prediction for 1200 sqft house: ${linear_model.predict(X_test)[0]:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83801fd2",
   "metadata": {},
   "source": [
    "## Second Example\n",
    "The second example is from an earlier lab with multiple features. The final parameter values and predictions are very close to the results from the un-normalized 'long-run' from that lab. That un-normalized run took hours to produce results, while this is nearly instantaneous. The closed-form solution work well on smaller data sets such as these but can be computationally demanding on larger data sets. \n",
    ">The closed-form solution does not require normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0b4e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.24e+03 3.00e+00 1.00e+00 6.40e+01]\n",
      " [1.95e+03 3.00e+00 2.00e+00 1.70e+01]\n",
      " [1.72e+03 3.00e+00 2.00e+00 4.20e+01]\n",
      " [1.96e+03 3.00e+00 2.00e+00 1.50e+01]\n",
      " [1.31e+03 2.00e+00 1.00e+00 1.40e+01]\n",
      " [8.64e+02 2.00e+00 1.00e+00 6.60e+01]\n",
      " [1.84e+03 3.00e+00 1.00e+00 1.70e+01]\n",
      " [1.03e+03 3.00e+00 1.00e+00 4.30e+01]\n",
      " [3.19e+03 4.00e+00 2.00e+00 8.70e+01]\n",
      " [7.88e+02 2.00e+00 1.00e+00 8.00e+01]\n",
      " [1.20e+03 2.00e+00 2.00e+00 1.70e+01]\n",
      " [1.56e+03 2.00e+00 1.00e+00 1.80e+01]\n",
      " [1.43e+03 3.00e+00 1.00e+00 2.00e+01]\n",
      " [1.22e+03 2.00e+00 1.00e+00 1.50e+01]\n",
      " [1.09e+03 2.00e+00 1.00e+00 6.40e+01]\n",
      " [8.48e+02 1.00e+00 1.00e+00 1.70e+01]\n",
      " [1.68e+03 3.00e+00 2.00e+00 2.30e+01]\n",
      " [1.77e+03 3.00e+00 2.00e+00 1.80e+01]\n",
      " [1.04e+03 3.00e+00 1.00e+00 4.40e+01]\n",
      " [1.65e+03 2.00e+00 1.00e+00 2.10e+01]\n",
      " [1.09e+03 2.00e+00 1.00e+00 3.50e+01]\n",
      " [1.32e+03 3.00e+00 1.00e+00 1.40e+01]\n",
      " [1.59e+03 0.00e+00 1.00e+00 2.00e+01]\n",
      " [9.72e+02 2.00e+00 1.00e+00 7.30e+01]\n",
      " [1.10e+03 3.00e+00 1.00e+00 3.70e+01]\n",
      " [1.00e+03 2.00e+00 1.00e+00 5.10e+01]\n",
      " [9.04e+02 3.00e+00 1.00e+00 5.50e+01]\n",
      " [1.69e+03 3.00e+00 1.00e+00 1.30e+01]\n",
      " [1.07e+03 2.00e+00 1.00e+00 1.00e+02]\n",
      " [1.42e+03 3.00e+00 2.00e+00 1.90e+01]\n",
      " [1.16e+03 3.00e+00 1.00e+00 5.20e+01]\n",
      " [1.94e+03 3.00e+00 2.00e+00 1.20e+01]\n",
      " [1.22e+03 2.00e+00 2.00e+00 7.40e+01]\n",
      " [2.48e+03 4.00e+00 2.00e+00 1.60e+01]\n",
      " [1.20e+03 2.00e+00 1.00e+00 1.80e+01]\n",
      " [1.84e+03 3.00e+00 2.00e+00 2.00e+01]\n",
      " [1.85e+03 3.00e+00 2.00e+00 5.70e+01]\n",
      " [1.66e+03 3.00e+00 2.00e+00 1.90e+01]\n",
      " [1.10e+03 2.00e+00 2.00e+00 9.70e+01]\n",
      " [1.78e+03 3.00e+00 2.00e+00 2.80e+01]\n",
      " [2.03e+03 4.00e+00 2.00e+00 4.50e+01]\n",
      " [1.78e+03 4.00e+00 2.00e+00 1.07e+02]\n",
      " [1.07e+03 2.00e+00 1.00e+00 1.00e+02]\n",
      " [1.55e+03 3.00e+00 1.00e+00 1.60e+01]\n",
      " [1.95e+03 3.00e+00 2.00e+00 1.60e+01]\n",
      " [1.22e+03 2.00e+00 2.00e+00 1.20e+01]\n",
      " [1.62e+03 3.00e+00 1.00e+00 1.60e+01]\n",
      " [8.16e+02 2.00e+00 1.00e+00 5.80e+01]\n",
      " [1.35e+03 3.00e+00 1.00e+00 2.10e+01]\n",
      " [1.57e+03 3.00e+00 1.00e+00 1.40e+01]\n",
      " [1.49e+03 3.00e+00 1.00e+00 5.70e+01]\n",
      " [1.51e+03 2.00e+00 1.00e+00 1.60e+01]\n",
      " [1.10e+03 3.00e+00 1.00e+00 2.70e+01]\n",
      " [1.76e+03 3.00e+00 2.00e+00 2.40e+01]\n",
      " [1.21e+03 2.00e+00 1.00e+00 1.40e+01]\n",
      " [1.47e+03 3.00e+00 2.00e+00 2.40e+01]\n",
      " [1.77e+03 3.00e+00 2.00e+00 8.40e+01]\n",
      " [1.65e+03 3.00e+00 1.00e+00 1.90e+01]\n",
      " [1.03e+03 3.00e+00 1.00e+00 6.00e+01]\n",
      " [1.12e+03 2.00e+00 2.00e+00 1.60e+01]\n",
      " [1.15e+03 3.00e+00 1.00e+00 6.20e+01]\n",
      " [8.16e+02 2.00e+00 1.00e+00 3.90e+01]\n",
      " [1.04e+03 3.00e+00 1.00e+00 2.50e+01]\n",
      " [1.39e+03 3.00e+00 1.00e+00 6.40e+01]\n",
      " [1.60e+03 3.00e+00 2.00e+00 2.90e+01]\n",
      " [1.22e+03 3.00e+00 1.00e+00 6.30e+01]\n",
      " [1.07e+03 2.00e+00 1.00e+00 1.00e+02]\n",
      " [2.60e+03 4.00e+00 2.00e+00 2.20e+01]\n",
      " [1.43e+03 3.00e+00 1.00e+00 5.90e+01]\n",
      " [2.09e+03 3.00e+00 2.00e+00 2.60e+01]\n",
      " [1.79e+03 4.00e+00 2.00e+00 4.90e+01]\n",
      " [1.48e+03 3.00e+00 2.00e+00 1.60e+01]\n",
      " [1.04e+03 3.00e+00 1.00e+00 2.50e+01]\n",
      " [1.43e+03 3.00e+00 1.00e+00 2.20e+01]\n",
      " [1.16e+03 3.00e+00 1.00e+00 5.30e+01]\n",
      " [1.55e+03 3.00e+00 2.00e+00 1.20e+01]\n",
      " [1.98e+03 3.00e+00 2.00e+00 2.20e+01]\n",
      " [1.06e+03 3.00e+00 1.00e+00 5.30e+01]\n",
      " [1.18e+03 2.00e+00 1.00e+00 9.90e+01]\n",
      " [1.36e+03 2.00e+00 1.00e+00 1.70e+01]\n",
      " [9.60e+02 3.00e+00 1.00e+00 5.10e+01]\n",
      " [1.46e+03 3.00e+00 2.00e+00 1.60e+01]\n",
      " [1.45e+03 3.00e+00 2.00e+00 2.50e+01]\n",
      " [1.21e+03 2.00e+00 1.00e+00 1.50e+01]\n",
      " [1.55e+03 3.00e+00 2.00e+00 1.60e+01]\n",
      " [8.82e+02 3.00e+00 1.00e+00 4.90e+01]\n",
      " [2.03e+03 4.00e+00 2.00e+00 4.50e+01]\n",
      " [1.04e+03 3.00e+00 1.00e+00 6.20e+01]\n",
      " [1.62e+03 3.00e+00 1.00e+00 1.60e+01]\n",
      " [8.03e+02 2.00e+00 1.00e+00 8.00e+01]\n",
      " [1.43e+03 3.00e+00 2.00e+00 2.10e+01]\n",
      " [1.66e+03 3.00e+00 1.00e+00 6.10e+01]\n",
      " [1.54e+03 3.00e+00 1.00e+00 1.60e+01]\n",
      " [9.48e+02 3.00e+00 1.00e+00 5.30e+01]\n",
      " [1.22e+03 2.00e+00 2.00e+00 1.20e+01]\n",
      " [1.43e+03 2.00e+00 1.00e+00 4.30e+01]\n",
      " [1.66e+03 3.00e+00 2.00e+00 1.90e+01]\n",
      " [1.21e+03 3.00e+00 1.00e+00 2.00e+01]\n",
      " [1.05e+03 2.00e+00 1.00e+00 6.50e+01]] [300.   509.8  394.   540.   415.   230.   560.   294.   718.2  200.\n",
      " 302.   468.   374.2  388.   282.   311.8  401.   449.8  301.   502.\n",
      " 340.   400.28 572.   264.   304.   298.   219.8  490.7  216.96 368.2\n",
      " 280.   526.87 237.   562.43 369.8  460.   374.   390.   158.   426.\n",
      " 390.   277.77 216.96 425.8  504.   329.   464.   220.   358.   478.\n",
      " 334.   426.98 290.   463.   390.8  354.   350.   460.   237.   288.3\n",
      " 282.   249.   304.   332.   351.8  310.   216.96 666.34 330.   480.\n",
      " 330.3  348.   304.   384.   316.   430.4  450.   284.   275.   414.\n",
      " 258.   378.   350.   412.   373.   225.   390.   267.4  464.   174.\n",
      " 340.   430.   440.   216.   329.   388.   390.   356.   257.8 ]\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "X_train, y_train = load_house_data()\n",
    "X_features = ['size(sqft)','bedrooms','floors','age']\n",
    "print(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5269cbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3a8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [  0.27 -32.62 -67.25  -1.47], b = 220.42\n"
     ]
    }
   ],
   "source": [
    "b = linear_model.intercept_\n",
    "w = linear_model.coef_\n",
    "print(f\"w = {w:}, b = {b:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e058c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on training set:\n",
      " [295.18 485.98 389.52 492.15]\n",
      "prediction using w,b:\n",
      " [295.18 485.98 389.52 492.15]\n",
      "Target values \n",
      " [300.  509.8 394.  540. ]\n",
      " predicted price of a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old = $318709.09\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prediction on training set:\\n {linear_model.predict(X_train)[:4]}\" )\n",
    "print(f\"prediction using w,b:\\n {(X_train @ w + b)[:4]}\")\n",
    "print(f\"Target values \\n {y_train[:4]}\")\n",
    "\n",
    "x_house = np.array([1200, 3,1, 40]).reshape(-1,4)\n",
    "x_house_predict = linear_model.predict(x_house)[0]\n",
    "print(f\" predicted price of a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old = ${x_house_predict*1000:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66701846",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "In this lab you:\n",
    "- utilized an open-source machine learning toolkit, scikit-learn\n",
    "- implemented linear regression using a close-form solution from that toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a84b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
